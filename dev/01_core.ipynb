{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.test import *\n",
    "from local.imports import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Basic functions used in the fastai library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime type checking is handy, so let's make it easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "#NB: Please don't move this to a different line or module, since it's used in testing `get_source_link`\n",
    "def chk(f): return typechecked(always=True)(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorator for a function to check that type-annotated arguments receive arguments of the right type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chk\n",
    "def test_chk(a:int=1): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chk(1)\n",
    "test_chk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda: test_chk('a'), contains='\"a\" must be int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monkey-patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "Tensor.ndim = property(lambda x: x.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "#### `Tensor.ndim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an `ndim` property to `Tensor` with same semantics as [numpy ndim](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.ndim.html), which allows tensors to be used in matplotlib and other places that assume this property exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(torch.tensor([1,2]).ndim,1)\n",
    "test_eq(torch.tensor(1).ndim,0)\n",
    "test_eq(torch.tensor([[1]]).ndim,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "Path.ls = lambda o: list(o.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "#### `Path.ls`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an `ls()` method to `pathlib.Path` which is simply defined as `list(Path.iterdir())`, mainly for convenience in REPL environments such as notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('_09_data_blocks_tutorial_vision.ipynb')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Path().ls()\n",
    "assert len(t)>0\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ifnone(a, b):\n",
    "    \"`b` if `a` is None else `a`\"\n",
    "    return b if a is None else a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `b if a is None else a` is such a common pattern, we wrap it in a function. However, be careful, because python will evaluate *both* `a` and `b` when calling `ifnone` (which it doesn't do if using the `if` version directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ifnone(None,1), 1)\n",
    "test_eq(ifnone(2   ,1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def noop (x, *args, **kwargs):\n",
    "    \"Do nothing\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(noop(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def noops(self, x, *args, **kwargs):\n",
    "    \"Do nothing (method)\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _t(): foo=noops\n",
    "test_eq(_t().foo(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def range_of(x):\n",
    "    \"All indices of collection `x` (i.e. `list(range(len(x)))`)\"\n",
    "    return list(range(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(range_of([1,1,1,1]), [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_iter(o):\n",
    "    \"Test whether `o` can be used in a `for` loop\"\n",
    "    #Rank 0 tensors in PyTorch are not really iterable\n",
    "    return isinstance(o, (Iterable,Generator)) and getattr(o,'ndim',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_iter([1])\n",
    "assert not is_iter(torch.tensor(1))\n",
    "assert is_iter(torch.tensor([1,2]))\n",
    "assert (o for o in range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mapper(f):\n",
    "    \"Create a function that maps `f` over an input collection\"\n",
    "    return lambda o: [f(o_) for o_ in o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mapper(lambda o:o*2)\n",
    "test_eq(func(range(3)),[0,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_cross_image(bw=True):\n",
    "    \"Create a tensor containing a cross image, either `bw` (True) or color\"\n",
    "    if bw:\n",
    "        im = torch.zeros(5,5)\n",
    "        im[2,:] = 1.\n",
    "        im[:,2] = 1.\n",
    "    else:\n",
    "        im = torch.zeros(3,5,5)\n",
    "        im[0,2,:] = 1.\n",
    "        im[1,:,2] = 1.\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def coll_repr(c, max=1000):\n",
    "    \"String repr of up to `max` items of (possibly lazy) collection `c`\"\n",
    "    return f'(#{len(c)}) [' + ','.join(itertools.islice(map(str,c), 10)) + ('...'\n",
    "            if len(c)>10 else '') + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(coll_repr(range(1000)), '(#1000) [0,1,2,3,4,5,6,7,8,9...]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def partialler(f, *args, order=None, **kwargs):\n",
    "    \"Like `functools.partial` but also copies over docstring\"\n",
    "    fnew = partial(f,*args,**kwargs)\n",
    "    fnew.__doc__ = f.__doc__\n",
    "    if order is not None: fnew.order=order\n",
    "    elif hasattr(f,'order'): fnew.order=f.order\n",
    "    return fnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _f(x,a=1):\n",
    "    \"test func\"\n",
    "    return x+a\n",
    "_f.order=1\n",
    "\n",
    "f = partialler(_f, a=2)\n",
    "test_eq(f.order, 1)\n",
    "f = partialler(_f, a=2, order=3)\n",
    "test_eq(f.__doc__, \"test func\")\n",
    "test_eq(f.order, 3)\n",
    "test_eq(f(3), _f(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def custom_dir(c, add:List):\n",
    "    \"Implement custom `__dir__`, adding `add` to `cls`\"\n",
    "    return dir(type(c)) + list(c.__dict__.keys()) + add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_props(f, n=2):\n",
    "    \"Create properties passing each of `range(n)` to f\"\n",
    "    return (property(partial(f,i)) for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(): a,b = add_props(lambda i,x:i*2)\n",
    "\n",
    "t = _T()\n",
    "test_eq(t.a,0)\n",
    "test_eq(t.b,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick way to generate, for instance, *train* and *valid* versions of a property. See `DataBunch` definition for an example of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def add_docs(cls, **docs):\n",
    "    \"Copy values from `docs` to `cls` docstrings, and confirm all public methods are documented\"\n",
    "    for k,v in docs.items(): getattr(cls,k).__doc__ = v\n",
    "    # List of public callables without docstring\n",
    "    nodoc = [c for n,c in vars(cls).items() if isinstance(c,Callable)\n",
    "             and not n.startswith('_') and c.__doc__ is None]\n",
    "    assert not nodoc, f\"Missing docs: {nodoc}\"\n",
    "    assert cls.__doc__ is not None, f\"Missing class docs: {cls}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def docs(cls):\n",
    "    \"Decorator version of `add_docs\"\n",
    "    add_docs(cls, **cls._docs)\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GetAttr -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GetAttr:\n",
    "    \"Inherit from this to have all attr accesses in `self._xtra` passed down to `self.default`\"\n",
    "    _xtra=[]\n",
    "    def __getattr__(self,k):\n",
    "        assert self._xtra, \"Inherited from `GetAttr` but no `_xtra` attrs listed\"\n",
    "        if k in self._xtra: return getattr(self.default, k)\n",
    "        raise AttributeError(k)\n",
    "    def __dir__(self): return custom_dir(self, self._xtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _C(GetAttr): default,_xtra = 'Hi',['lower']\n",
    "\n",
    "t = _C()\n",
    "test_eq(t.lower(), 'hi')\n",
    "test_fail(lambda: t.upper())\n",
    "assert 'lower' in dir(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _mask2idxs(mask):\n",
    "    mask = list(mask)\n",
    "    if isinstance(mask[0],bool): return [i for i,m in enumerate(mask) if m]\n",
    "    return [int(i) for i in mask]\n",
    "\n",
    "def _listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, (str,np.ndarray,Tensor)): return [o]\n",
    "    if is_iter(o): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class L(GetAttr):\n",
    "    \"Behaves like a list of `items` but can also index with list of indices or masks\"\n",
    "    _xtra =  [o for o in dir(list) if not o.startswith('_')]\n",
    "\n",
    "    def __init__(self, items=None, *rest, use_list=False):\n",
    "        items = ifnone(items, [])\n",
    "        self.items = self.default = list(items) if use_list else _listify(items)\n",
    "        self.items += list(rest)\n",
    "        \n",
    "    def __new__(cls, items=None, *args,**kwargs): return items if isinstance(items,L) else super().__new__(cls)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self): return f'{coll_repr(self)}'\n",
    "    def __eq__(self,b): return all_equal(b,self)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __add__ (a,b): return L(a.items+_listify(b))\n",
    "    def __radd__(a,b): return L(b)+a\n",
    "    def __addi__(a,b):\n",
    "        a.items += list(b)\n",
    "        return a\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        res = [self.items[i] for i in _mask2idxs(idx)] if is_iter(idx) else self.items[idx]\n",
    "        if isinstance(res,(tuple,list)) and not isinstance(res,L): res = L(res)\n",
    "        return res\n",
    "    \n",
    "    def __setitem__(self, idx, o):\n",
    "        idx = idx if isinstance(idx,L) else _listify(idx) \n",
    "        if not is_iter(o): o = [o]*len(idx)\n",
    "        for i,o_ in zip(idx,o): self.items[i] = o_\n",
    "\n",
    "    def mapped(self, f):    return L(map(f, self))\n",
    "    def zipped(self):       return L(zip(*self))\n",
    "    def itemgot(self, idx): return self.mapped(itemgetter(idx))\n",
    "    def attrgot(self, k):   return self.mapped(attrgetter(k))\n",
    "    \n",
    "    _docs=dict(mapped=\"Create new `L` with `f` applied to all `items`\",\n",
    "              zipped=\"Create new `L` with `zip(*items)`\",\n",
    "              itemgot=\"Create new `L` with item `idx` of all `items`\",\n",
    "              attrgot=\"Create new `L` with attr `k` of all `items`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#13) [h,11,10,j,0,k,0,5,4,3...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = L(range(12))\n",
    "\n",
    "test_eq(t, list(range(12)))\n",
    "test_ne(t, list(range(11)))\n",
    "test_eq(t[[1,2]], [1,2])\n",
    "test_eq(t[[False]*10 + [True,False]], [10])\n",
    "test_eq(t[torch.tensor(3)], 3)\n",
    "t.append(\"h\")\n",
    "test_eq(t[-1], \"h\")\n",
    "t.reverse()\n",
    "test_eq(t[0], \"h\")\n",
    "t[3] = \"h\"\n",
    "test_eq(t[3], \"h\")\n",
    "t[3,5] = (\"j\",\"k\")\n",
    "test_eq(t[3,5], [\"j\",\"k\"])\n",
    "t[4,6] = 0\n",
    "test_eq(t[4,6], [0,0])\n",
    "test_eq(t, L(t))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L()\n",
    "test_eq(t, [])\n",
    "t.append(1)\n",
    "test_eq(t, [1])\n",
    "t += [3,2]\n",
    "test_eq(t, [1,3,2])\n",
    "t = t + [4]\n",
    "test_eq(t, [1,3,2,4])\n",
    "t = 5 + t\n",
    "test_eq(t, [5,1,3,2,4])\n",
    "test_eq(L(1,2,3), [1,2,3])\n",
    "test_eq(L(1,2,3), L(1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.mapped\" class=\"doc_header\"><code>mapped</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>mapped</code>(**`f`**)\n",
       "\n",
       "Create new [`L`](/core.html#L) with `f` applied to all `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(range(4)).mapped(operator.neg), [0,-1,-2,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.zipped\" class=\"doc_header\"><code>zipped</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>zipped</code>()\n",
       "\n",
       "Create new [`L`](/core.html#L) with `zip(*items)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L([[1,2,3],'abc'])\n",
    "test_eq(t.zipped(), [(1, 'a'),(2, 'b'),(3, 'c')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.itemgot\" class=\"doc_header\"><code>itemgot</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>itemgot</code>(**`idx`**)\n",
       "\n",
       "Create new [`L`](/core.html#L) with item `idx` of all `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.itemgot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.itemgot(1), [2,'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.attrgot\" class=\"doc_header\"><code>attrgot</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>attrgot</code>(**`k`**)\n",
       "\n",
       "Create new [`L`](/core.html#L) with attr `k` of all `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.attrgot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [SimpleNamespace(a=1,b=2),SimpleNamespace(a=3,b=4)]\n",
    "test_eq(L(a).attrgot('b'), [2,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions using `L`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(L(None),[])\n",
    "test_eq(L([1,2,3]),[1,2,3])\n",
    "test_eq(L(L([1,2,3])),[1,2,3])\n",
    "test_ne(L([1,2,3]),[1,2,])\n",
    "test_eq(L('abc'),['abc'])\n",
    "test_eq(L(range(0,3)),[0,1,2])\n",
    "test_eq(L(o for o in range(0,3)),[0,1,2])\n",
    "test_eq(L(torch.tensor(0)),[torch.tensor(0)])\n",
    "test_eq(L([torch.tensor(0),torch.tensor(1)]),[torch.tensor(0),torch.tensor(1)])\n",
    "test_eq(L(torch.tensor([0.,1.1]))[0],torch.tensor([0.,1.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tuplify(o):\n",
    "    \"Make `o` a tuple\"\n",
    "    return tuple(L(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tuplify(None),())\n",
    "test_eq(tuplify([1,2,3]),(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tensor(x, *rest):\n",
    "    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n",
    "    if len(rest): x = tuplify(x)+rest\n",
    "    # Pytorch bug in dataloader using num_workers>0\n",
    "    if isinstance(x, (tuple,list)) and len(x)==0: return tensor(0)\n",
    "    res = torch.tensor(x) if isinstance(x, (tuple,list)) else as_tensor(x)\n",
    "    if res.dtype is torch.int32:\n",
    "        warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n",
    "        return res.long()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tensor(array([1,2,3])), torch.tensor([1,2,3]))\n",
    "test_eq(tensor(1,2,3), torch.tensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@chk\n",
    "def compose(*funcs: Callable):\n",
    "    \"Create a function that composes all functions in `funcs`, passing along remaining `*args` and `**kwargs` to all\"\n",
    "    def _inner(x, *args, **kwargs):\n",
    "        for f in L(funcs): x = f(x, *args, **kwargs)\n",
    "        return x\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda o,p=0: (o*2)+p\n",
    "f2 = lambda o,p=1: (o+1)/p\n",
    "test_eq(f2(f1(3)), compose(f1,f2)(3))\n",
    "test_eq(f2(f1(3,p=3),p=3), compose(f1,f2)(3,p=3))\n",
    "test_eq(f2(f1(3,  3),  3), compose(f1,f2)(3,  3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniqueify(x, sort=False, bidir=False, start=None):\n",
    "    \"Return the unique elements in `x`, optionally `sort`-ed, optionally return the reverse correspondance.\"\n",
    "    res = list(OrderedDict.fromkeys(x).keys())\n",
    "    if start is not None: res = L(start)+res\n",
    "    if sort: res.sort()\n",
    "    if bidir: return res, {v:k for k,v in enumerate(res)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(set(uniqueify([1,1,0,5,0,3])),{0,1,3,5})\n",
    "test_eq(uniqueify([1,1,0,5,0,3], sort=True),[0,1,3,5])\n",
    "v,o = uniqueify([1,1,0,5,0,3], bidir=True)\n",
    "test_eq(v,[1,0,5,3])\n",
    "test_eq(o,{1:0, 0: 1, 5: 2, 3: 3})\n",
    "v,o = uniqueify([1,1,0,5,0,3], sort=True, bidir=True)\n",
    "test_eq(v,[0,1,3,5])\n",
    "test_eq(o,{0:0, 1: 1, 3: 2, 5: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def setify(o): return o if isinstance(o,set) else set(L(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(setify(None),set())\n",
    "test_eq(setify('abc'),{'abc'})\n",
    "test_eq(setify([1,2,2]),{1,2})\n",
    "test_eq(setify(range(0,3)),{0,1,2})\n",
    "test_eq(setify({1,2}),{1,2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def mask2idxs(mask):\n",
    "    \"Convert bool mask or index list to index `L`\"\n",
    "    return L(_mask2idxs(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(mask2idxs([False,True,False,True]), [1,3])\n",
    "test_eq(mask2idxs(tensor([1,2,3])), [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_listy(x):\n",
    "    \"`isinstance(x, (tuple,list,L))`\"\n",
    "    return isinstance(x, (tuple,list,L,slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_listy([1])\n",
    "assert is_listy(L([1]))\n",
    "assert is_listy(slice(2))\n",
    "assert not is_listy(torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
